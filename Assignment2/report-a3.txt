   Report - Assignment 3 Computer Vision 2014-2015
`~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
	
	Tim Kuipers (3149099 (old) or F141459 (new)) 
		color model, offline tracking initialization
	
	Jeroen van de Ven (F141192) 
		online tracking steps, drawing (opengl), output

														
=======================================================

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

        _   _____  ___   ____                                                                                                                                                                                            
|\  |  / \    |   |     /                                                       
| \ | |   |   |   |__   \___                                                      
|  \| |   |   |   |         \                                               
|   |  \_/    |   |___  ____/                                                     


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   

Tim Kuipers 

---

MixtureColorModel  .h / .cpp : 

This class is used to store the gaussian mixture color models of the four people in the video's.
Note that it is adapted speficically to our setting, it uses 4 Gaussian Mixture Models (cv::EM)
which are initialized from a single frame for which pixel is classified by hand 
(see data\cam1frame752-manualforeground-colored.bmp).

We've tested on gaussian mixture models which used part and whole of the covariance matrix of the 
underlying Gaussians.
Examples of the workings of these color models are given by A) output\generated_output-diagonal_matrix.bmp
and B) data\generated_output-normal_cov_matrix.bmp .
These are generated by converting the color of each pixel to the color model with the closest distence, i.e.
the color model assigning the highest probability.
For image A we restricted the covariance matrix to a diagonal matrix, meaning the underlying gaussian distributions
didn´t make use of covariances - merely the variances were modelled.
Since B was generated by making full use of the covariance matrix and B seems to be less noisy, we concluded
that using unrestricted 

We've implemented a workaround in order for the Gaussian Mixture models to be saved and loaded, leading to
smaller run times, since the training of the models only has to be performed once. Note that a workaround
was needed, since the standard cv::EM's weights, covs and means parameters are read-only.

The distance function between a given color and a color model is given by the negative log likelihood of
the model given the color.

---

Cluster assignment by color models :

In VoxelTracker::assignClusterLabelBasedOnColor() (in VoxelTracker.h) these distances were then used to 
estimate the cluster centers initially. Because the color distance measure is not linear, we couldn't add 
the distances of the voxels corresponding pixels up for a given color model in order to get a final estimate 
of the distance of a voxel to a given color model. (Note that one voxel corresponds to a pixel in each of 
the cameras.)
Instead, a majority voting scheme was implemented. For each view the color model with the highest 
likelihood got a vote; the voxel was then assigned the label corresponding to the color model with the 
highest number of votes, or in case of a tie, one of the highest voted colors models was picked randomly.
For voxel areas generated because they are occluded in every view by different people, the voting scheme 
results in a noisy classification of voxels, which can make it easier to eventually remove these ghost voxels.

---

Initial cluster center estimation :

In VoxelTracker::update() (in VoxelTracker.cpp) the labellings of the voxels are used in order to get a 
first estimate of the cluster centers. In order to take (less) care of outliers, we did not just look 
at the arithmatic mean of the data. Instead we computed a weighted mean, where the weights are a function 
of the distance of a voxel to the arithmetic mean - the farther away a voxel is from the arithmetic mean, 
the less (exponentially) it influences the weighted mean. As such, outliers contribute less to the eventual 
cluster center. This caused the cluster centers to move more toward the cloud where the largest amount of 
correspondingly labelled voxels were, eventhough substantial parts of other people were mislabelled.

---

About the mislabelling: note that the people in the video's wear similarly colored clothing. A couple 
of shirts and pants have a similar blue color. It is not surprising that these colors were confused.

=======================================================

Jeroen van de Ven

---

struct Cluster:

Clusters are given a center position, a color, a colormodel and a path. 
'Path' is simply the history of the center positions and is used to for drawing.

---

Drawing the cluster path history: use the 'a' key in the program to toggle this mode.
It runs Glut::drawClusterPaths

---

Online tracking:

This is implemented mostly in VoxelTracker. VoxelTracker::update is called each time
a new frame is processed. It performs the steps in III.1 through III.6 making use of 
assignClusterLabelBasedOnColor by Tim. 

VoxelTracker::update also outputs the newly calculated centers of the clusters to a text file.
(the assignment was ambiguous here, in section III it was specified to add an image trace
of the paths but in the 'Submission' section a text version was requested. We did both.

---

Drawing:

Cluster centers are (always) drawn as squares on the floor of the cube (Glut::drawClusterPositions)

---

Results analysis

Because we used input video's with 4 people that sometimes walk entirely out of the picture
on some cameras, the clusters sometimes get lost. Either of two things happen then: (a) The 
cluster center floats around, or (b) A different person gets split into two clusters.

Examples of (a): 0:15 etc
Examples of (b): 0:11, 0:12 etc

Whenever all the people are in the model, the clusters work well and are stable. We did not
consider the quality of these input video's when we decided to use them, only that they had 4
people which would have been more challenging. It turns out the fact that not all people
are always in the model is the most important factor that makes these input video's difficult.

=======================================================

Some General Notes

---

Note that in the assignment it says:
"III.2 Based on the color distance to the models (not the spatial distance), label each of 
the unlabeled voxels with a person ID."

Labeling the unlabeled voxels only was used in making the video of the classification after clustering (B),
but not in the video of classification by color model alone (A).
We thought that without this feature it would be easier to see from the video (A) what the inner workings
of the gaussian mixture color model lead to.

For (A) visit http://youtu.be/r0iC1uoi6KM?list=UUI7xKLynkgJ2AofPG3FSOcA
For (B) visit http://youtu.be/Om43CSQArWg?list=UUI7xKLynkgJ2AofPG3FSOcA
Be sure not to check out the rest of my playlist, if you don't want you brain fried.

The trajectories are given by (as requested in a text file)
A> output/trajectories - color models.txt
B> output/trajectories - clustering.txt

And images by
A> data\paths of color models.png
B> data\paths of clusters.png

Note that the images are in different orientations!

